{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ad52d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\elaine m paily\\appdata\\roaming\\python\\python39\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\elaine m paily\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -dna (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nyio (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yodbc (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ytz (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -dna (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nyio (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yodbc (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ytz (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 483, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: '{version}'\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33cee825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few document texts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('A Library Management Game', 'a report on a research project'),\n",
       " ('Findings of the documentary analysis included the following', ''),\n",
       " ('Definitions of \"browsing\" varied greatly', 'self-indulgence'),\n",
       " ('design features were developed, and included the following', ''),\n",
       " ('his own professional idiom as belonging to one great whole', '')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------Reading CISI.ALL------\n",
    "with open('E:\\\\cisi\\\\CISI.ALL', 'r') as f:\n",
    "    documents = f.readlines()\n",
    "\n",
    "# Process the document text into a dictionary (DocumentID -> DocumentText)\n",
    "doc_texts = {}\n",
    "for line in documents:\n",
    "    # Skip lines that don't contain a colon (could be empty or malformed)\n",
    "    if ':' not in line:\n",
    "        continue\n",
    "    \n",
    "    # Split the line into DocumentID and DocumentText\n",
    "    doc_id, doc_text = line.split(\":\", 1)\n",
    "    doc_texts[doc_id.strip()] = doc_text.strip()\n",
    "\n",
    "# Display first few document texts\n",
    "print(\"First few document texts:\")\n",
    "list(doc_texts.items())[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "474a1bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few queries:\n",
      "Query 1: 'concerns', 'descriptive', 'approximate', 'difficulties', 'content', 'relevance','articles'));\n",
      "Query 2: 'pertinent', 'response', 'computer-ready') ) );\n",
      "Query 3: 'researchers',\t'encounter'), 'coded', 'printing', 'publishing'), 'planned', 'saving', 'articles') );\n",
      "Query 4: 'possibilities','inclusion', 'analysis'), 'volume', 'speed'), 'compounds', 'chemical'), 'extended', 'encoding', 'matching'));\n",
      "Query 5: 'information') );\n"
     ]
    }
   ],
   "source": [
    "# -----Reading the CISI.BLN file------\n",
    "import re\n",
    "\n",
    "with open('E:\\\\cisi\\\\CISI.BLN', 'r') as f:\n",
    "    boolean_queries = f.readlines()\n",
    "\n",
    "# Prepare a list to store queries\n",
    "queries = []\n",
    "current_query = \"\"\n",
    "inside_query = False\n",
    "\n",
    "# Loop through each line to process the queries\n",
    "for line in boolean_queries:\n",
    "    line = line.strip()\n",
    "\n",
    "    # Skip empty lines or comments\n",
    "    if not line or line.startswith('#'):\n",
    "        continue\n",
    "\n",
    "    # Check for new topic (i.e., queries beginning with #q1=, #q2=, ...)\n",
    "    match = re.match(r'#q(\\d+)\\s*=', line)\n",
    "    if match:\n",
    "        if inside_query and current_query:\n",
    "            queries.append(current_query.strip())  # Append the current query before starting new one\n",
    "\n",
    "        # Start a new query\n",
    "        current_query = line.split(\"=\", 1)[1].strip()\n",
    "        inside_query = True\n",
    "    else:\n",
    "        # Continue accumulating lines for the current query\n",
    "        current_query += \" \" + line.strip()\n",
    "\n",
    "        # If the line ends with a semicolon, the query is complete\n",
    "        if current_query.endswith(';'):\n",
    "            queries.append(current_query.strip())  # Append the completed query\n",
    "            current_query = \"\"  # Reset for the next query\n",
    "            inside_query = False\n",
    "\n",
    "# Show the first few processed queries (e.g., the first 5)\n",
    "print(\"First few queries:\")\n",
    "for i, query in enumerate(queries[:5]):  # Adjust the number 5 to display more/less queries\n",
    "    print(f\"Query {i+1}: {query}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9197491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few topics:\n",
      "Topic Fuzzy Requests: An Approach to Weighted Boolean Searches\n",
      "Topic Measurement in Information Science: Objective and Subjective Metrical Space\n",
      "Topic information space.  These two spaces are like maps and landscapes: each\n",
      "Topic distinguished: search service (e.g., SDC, Lockheed), customized service\n",
      "Topic to the emergence of three additional nonprofit library networks: the\n"
     ]
    }
   ],
   "source": [
    "# ------Reading CISI.QRY (Query Topics)------\n",
    "with open('E:\\\\cisi\\\\CISI.QRY', 'r') as f:\n",
    "    topics = f.readlines()\n",
    "\n",
    "# Process into a dictionary (TopicID -> Topic Description)\n",
    "topic_descriptions = {}\n",
    "for line in topics:\n",
    "    line = line.strip()  # Remove any leading/trailing whitespace\n",
    "    if ':' in line:  # Ensure the line contains a colon\n",
    "        topic_id, description = line.split(\":\", 1)\n",
    "        topic_descriptions[topic_id.strip()] = description.strip()\n",
    "\n",
    "# Display first few topics\n",
    "print(\"First few topics:\")\n",
    "for i, (topic_id, description) in enumerate(topic_descriptions.items()):\n",
    "    if i < 5:  # Display only the first 5 topics\n",
    "        print(f\"Topic {topic_id}: {description}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2e7d0025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few relevance judgements for first few topics:\n",
      "Topic 1:\n",
      "  Document 28: 0\n",
      "  Document 35: 0\n",
      "  Document 38: 0\n",
      "  Document 42: 0\n",
      "  Document 43: 0\n",
      "Topic 2:\n",
      "  Document 29: 0\n",
      "  Document 68: 0\n",
      "  Document 197: 0\n",
      "  Document 213: 0\n",
      "  Document 214: 0\n",
      "Topic 3:\n",
      "  Document 60: 0\n",
      "  Document 85: 0\n",
      "  Document 114: 0\n",
      "  Document 123: 0\n",
      "  Document 126: 0\n"
     ]
    }
   ],
   "source": [
    "# -----Reading CISI.REL (Relevance Judgments)------\n",
    "import re\n",
    "\n",
    "with open('E:\\\\cisi\\\\CISI.REL', 'r') as f:\n",
    "    relevance_judgments = f.readlines()\n",
    "\n",
    "# Process into a dictionary (TopicID -> {DocumentID -> Relevance})\n",
    "relevance = {}\n",
    "for line in relevance_judgments:\n",
    "    line = line.strip()  # Remove leading/trailing whitespace\n",
    "    if line:  # Ensure the line is not empty\n",
    "        parts = re.split(r'\\s+', line)  # Split on one or more spaces/tabs\n",
    "        if len(parts) >= 2:  # Ensure there are at least 2 elements (topic_id, doc_id)\n",
    "            topic_id, doc_id = parts[0], parts[1]\n",
    "            if topic_id not in relevance:\n",
    "                relevance[topic_id] = {}\n",
    "            relevance[topic_id][doc_id] = 0  # Assuming relevance is 0 for now (or could be adjusted)\n",
    "\n",
    "# Display first few relevance judgments for the first few topics\n",
    "print(\"\\nFirst few relevance judgements for first few topics:\")\n",
    "topic_count = 0\n",
    "max_topics_to_display = 3  # Change this to the number of topics you want to display\n",
    "for topic_id, doc_dict in list(relevance.items())[:max_topics_to_display]:\n",
    "    print(f\"Topic {topic_id}:\")\n",
    "    doc_count = 0\n",
    "    max_docs_to_display = 5  # Change this to the number of documents you want to display per topic\n",
    "    for doc_id, rel in doc_dict.items():\n",
    "        if doc_count < max_docs_to_display:\n",
    "            print(f\"  Document {doc_id}: {rel}\")\n",
    "            doc_count += 1\n",
    "    topic_count += 1\n",
    "    if topic_count >= max_topics_to_display:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c5aa4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Approach to Weighted Boolean Searches\n"
     ]
    }
   ],
   "source": [
    "#-----mapping topic descriptions to their coressponding numerical topic IDs-----\n",
    "topic_descriptions = {\n",
    "    \"1\": \"An Approach to Weighted Boolean Searches\",\n",
    "    \"2\": \"Objective and Subjective Metrical Space\",\n",
    "    \"3\": \"Each\",\n",
    "    \"4\": \"Search service (e.g., SDC, Lockheed), customized service\",\n",
    "    \"5\": \"Library Networks and Resource Sharing in the United States\",\n",
    "    \"6\": \"The Graph-Oriented\",\n",
    "    \"7\": \"y = a log(x + c) + b, where y is the ratio of the cumulative\",\n",
    "    \"8\": \"The Donau Project\",\n",
    "    \"9\": \"a general purpose domain oriented natural\",\n",
    "    \"10\": \"\",\n",
    "    \"11\": \"\",\n",
    "    \"12\": \"Refles\",\n",
    "    \"13\": \"An Electronic Filing Machine for the Office of the Future\",\n",
    "    \"14\": \"Retrieval Performance\",\n",
    "    \"15\": \"an abstract, a\",\n",
    "    \"16\": \"A Literature Measure of Intellectual Structure\",\n",
    "    \"17\": \"\",\n",
    "}\n",
    "\n",
    "# Check if '1' exists and print the description\n",
    "print(topic_descriptions.get(\"1\", \"Topic '1' not found\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "033e0edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Biomedical Literature',\n",
       " '(a) General survey method',\n",
       " 'base and characterized according to the five major types of failures',\n",
       " 'Findings of the documentary analysis included the following',\n",
       " 'is',\n",
       " '1958, and 1968 by the following criteria',\n",
       " 'COSATI is as follows',\n",
       " 'The Computer/Library Interface',\n",
       " 'achieved by substitution of codes with the highest zero',\n",
       " 'measures of cost were employed']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------Simulating retrieval results (random rankings)------\n",
    "import numpy as np\n",
    "\n",
    "num_runs = 3\n",
    "ranked_results = {}\n",
    "\n",
    "for topic_id in topic_descriptions:\n",
    "    # Randomly shuffle document IDs for each topic to simulate a retrieval run\n",
    "    doc_ids = list(doc_texts.keys())  # All document IDs\n",
    "    np.random.shuffle(doc_ids)  # Shuffle the list to simulate retrieval\n",
    "    ranked_results[topic_id] = doc_ids[:10]  # Select top 10 docs\n",
    "\n",
    "# Show the simulated retrieval results for a topic\n",
    "ranked_results[\"1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4210f68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TopicID</th>\n",
       "      <th>RankedDocuments</th>\n",
       "      <th>PooledRelevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Biomedical Literature, (a) General survey met...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[rests is this, Costs and Effectiveness in the...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[R and D Project Selection, The Magical Number...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[Expected Search Length, research libraries, o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[Aspect Abstracting, include, The Circulation ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TopicID                                    RankedDocuments  PooledRelevance\n",
       "0       1  [Biomedical Literature, (a) General survey met...              0.0\n",
       "1       2  [rests is this, Costs and Effectiveness in the...              0.0\n",
       "2       3  [R and D Project Selection, The Magical Number...              0.0\n",
       "3       4  [Expected Search Length, research libraries, o...              0.0\n",
       "4       5  [Aspect Abstracting, include, The Circulation ...              0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----Pooling results: For each topic, aggregate the relevance scores from the retrieval runs-----\n",
    "pooled_results = []\n",
    "\n",
    "for topic_id, ranked_docs in ranked_results.items():\n",
    "    relevance_scores = []\n",
    "    \n",
    "    for doc_id in ranked_docs:\n",
    "        # Get relevance score for the document (0 or 1)\n",
    "        rel_score = relevance.get(topic_id, {}).get(doc_id, 0)\n",
    "        relevance_scores.append(rel_score)\n",
    "    \n",
    "    # Pooling: We can either use majority voting or average pooling\n",
    "    pooled_relevance = np.mean(relevance_scores)  # Mean as the pooling method\n",
    "    pooled_results.append({\n",
    "        'TopicID': topic_id,\n",
    "        'RankedDocuments': ranked_docs,\n",
    "        'PooledRelevance': pooled_relevance\n",
    "    })\n",
    "\n",
    "# Convert pooled results into DataFrame for easier analysis\n",
    "import pandas as pd\n",
    "pooled_df = pd.DataFrame(pooled_results)\n",
    "\n",
    "# Display pooled results\n",
    "pooled_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d69dc9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 Ranked Documents: ['Biomedical Literature', 'General Survey Methods', 'Data Structures', 'Data Mining', 'Machine Learning']\n",
      "Relevance Data for Topic 1: {'Biomedical Literature': 1, 'General Survey Methods': 0, 'Data Structures': 0, 'Data Mining': 1, 'Machine Learning': 1}\n",
      "Topic 2 Ranked Documents: ['AI Research', 'Machine Learning', 'Data Mining', 'Data Visualization', 'AI Models']\n",
      "Relevance Data for Topic 2: {'AI Research': 1, 'Machine Learning': 1, 'Data Mining': 0, 'Data Visualization': 0, 'AI Models': 1}\n",
      "Document: Biomedical Literature, Relevance: 1\n",
      "Document: General Survey Methods, Relevance: 0\n",
      "Document: Data Structures, Relevance: 0\n",
      "Document: Data Mining, Relevance: 1\n",
      "Document: Machine Learning, Relevance: 1\n",
      "Number of relevant documents for topic 1: 3/5\n",
      "Relevance scores for topic 1: [1, 0, 0, 1, 1]\n",
      "Document: AI Research, Relevance: 1\n",
      "Document: Machine Learning, Relevance: 1\n",
      "Document: Data Mining, Relevance: 0\n",
      "Document: Data Visualization, Relevance: 0\n",
      "Document: AI Models, Relevance: 1\n",
      "Number of relevant documents for topic 2: 3/5\n",
      "Relevance scores for topic 2: [1, 1, 0, 0, 1]\n",
      "   TopicID                                    RankedDocuments  \\\n",
      "0        1  [Biomedical Literature, General Survey Methods...   \n",
      "1        2  [AI Research, Machine Learning, Data Mining, D...   \n",
      "\n",
      "   PooledRelevance  MAP  \n",
      "0                0  1.0  \n",
      "1                0  1.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def mean_average_precision(topic_id, retrieved_docs, relevance_data):\n",
    "    # Get relevance scores for the retrieved documents\n",
    "    relevance_scores = []\n",
    "    num_relevant = 0\n",
    "    for doc in retrieved_docs:\n",
    "        relevance_score = relevance_data.get(str(topic_id), {}).get(doc, 0)\n",
    "        relevance_scores.append(relevance_score)\n",
    "        if relevance_score > 0:\n",
    "            num_relevant += 1\n",
    "        print(f\"Document: {doc}, Relevance: {relevance_score}\")  # Debugging line\n",
    "    \n",
    "    # Check how many relevant documents are in the ranked list\n",
    "    print(f\"Number of relevant documents for topic {topic_id}: {num_relevant}/{len(retrieved_docs)}\")\n",
    "    \n",
    "    # Calculate and return MAP if there are valid relevance scores\n",
    "    if not relevance_scores:\n",
    "        return 0.0\n",
    "    \n",
    "    # Print the list of relevance scores to debug\n",
    "    print(f\"Relevance scores for topic {topic_id}: {relevance_scores}\")\n",
    "    \n",
    "    # Calculate MAP\n",
    "    return average_precision_score(relevance_scores, relevance_scores)\n",
    "\n",
    "# Debugging: Check if the documents match and print the results\n",
    "for topic_id in pooled_df['TopicID']:\n",
    "    print(f\"Topic {topic_id} Ranked Documents: {pooled_df.loc[pooled_df['TopicID'] == topic_id, 'RankedDocuments'].values[0]}\")\n",
    "    print(f\"Relevance Data for Topic {topic_id}: {relevance.get(str(topic_id), {})}\")\n",
    "\n",
    "# Apply MAP calculation to each topic\n",
    "pooled_df['MAP'] = pooled_df.apply(\n",
    "    lambda row: mean_average_precision(row['TopicID'], row['RankedDocuments'], relevance), axis=1\n",
    ")\n",
    "\n",
    "# Display the final results with MAP scores\n",
    "print(pooled_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d9c7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
